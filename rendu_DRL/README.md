Projet d'apprentissage par renforcement - Implémentation d'algorithmes classiques de RL
Ce projet vise à implémenter et tester différents algorithmes d'apprentissage par renforcement (RL) sur des environnements de jeu simples. Les algorithmes implémentés sont les suivants :

Partie 1 : Dynamic Programming
Création des contrats liés à un MDP (Processus de Décision Markovien).
Création de l'environnement "Line World" pour les tests initiaux.
Implémentation de l'algorithme "Policy Evaluation".
Implémentation de l'algorithme "Policy Iteration".
Implémentation de l'algorithme "Value Iteration".
Tests et vérifications de ces algorithmes sur l'environnement "Line World".
Création de l'environnement "Grid World" pour des tests plus complexes.
Tests et vérifications de ces algorithmes sur l'environnement "Grid World".
Évaluation sur l'environnement "Secret 1".

Partie 2 : Méthodes Monte Carlo
Implémentation d'un jeu "TicTacToe 1" pour les tests avec un joueur contre une IA aléatoire.
Implémentation de l'algorithme "Monte Carlo ES".
Implémentation de l'algorithme "On-policy first visit Monte Carlo Control".
Implémentation de l'algorithme "Off-policy Monte Carlo Control".
Tests et vérifications de ces algorithmes sur l'environnement "TicTacToe 1" et les environnements précédents.
Évaluation sur l'environnement "Secret 2".

Partie 3 : Temporal Difference Learning
Implémentation de l'algorithme Sarsa.
Implémentation de l'algorithme Q-Learning.
Implémentation de l'algorithme Expected Sarsa.
Tests et vérifications de ces algorithmes sur l'environnement "TicTacToe 1" et les environnements précédents.
(Optionnel) Implémentation de l'algorithme "n-step Q-Learning".
Évaluation sur l'environnement "Secret 3".
Partie 4 : Planning
Évaluation sur les environnements précédents.

Interface graphique et agent humain
L'implémentation comprend une interface graphique permettant d'observer chaque agent jouer et interagir avec un agent humain en ligne de commande.


Résultats
Les résultats obtenus pour chaque algorithme et environnement sont présentés dans le rapport du projet.


Comment utiliser le code
Clonez ce dépôt sur votre machine locale.
Exécutez les algorithmes souhaités à partir des fichiers correspondants.
L'interface graphique peut être lancée à l'aide d'une commande spécifique.
Les fichiers de sauvegarde des fonctions de politique, des fonctions de valeur et des fonctions d'action-value sont disponibles pour confirmation des résultats.


Auteurs:

AIT IDIR Adem
AZI Rabah abdelnour
DOROSENCO Nadejda
OULD AMARA Sofiane